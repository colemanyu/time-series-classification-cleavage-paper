\section{Results} \label{sec:results}
% The code implementing our method is available at 
% our project website
% \footnote{\href{https://github.com/colemanyu/time-series-classification-cleavage}{https://github.com/colemanyu/time-series-classification-cleavage}.}
% . 
% The dataset of this study is available at 
% \href{https://www.mirbase.org}{https://www.mirbase.org}. 
The code implementing our method is available at 
\url{https://github.com/colemanyu/time-series-classification-cleavage}. 
The dataset of this study is available at 
\url{https://www.mirbase.org}. 

In all experiments, the models were trained and tested using 5-fold cross-validation.
We retrieved 827 empirically validated sequences of pre-miRNAs.
There are 5p arm and 3p arm in each sequence.
For each arm, we defined a cleavage pattern and a non-cleavage pattern.
Three datasets, namely ``5p arm'', ``3p arm'', and ``multi-class'' were constructed by these patterns.
We refer to the cleavage patterns as positive instances and the non-cleavage patterns as negative instances.
The 5p arm dataset comprises 827 positive instances and an equal number of negative instances.
The 5p arm and 3p arm datasets are binary-class datasets.
The multi-class dataset comprises all patterns from both the 5p arm and the 3p arm.
There are 827 ``5p'' instances\footnote{Cleavage patterns from the 5p arm.}, 827 ``3p'' instances, and 1,654 negative instances.

For every fold in 5-fold cross-validation, the dataset was divided into a training set and a test set with sizes of 80\% and 20\% of the whole dataset, respectively.
We kept the class distribution approximately the same in each fold, since it is in the original dataset.
In each fold derived from the 5p arm and 3p arm datasets, the training set has a size of 1,323, and the test set has a size of 331.
In each fold derived from the multi-class dataset, the training set has a size of 2,262, and the test set has a size of 662.
We reported the average of the five classification metrics.

The ROCKET-based classifiers require all channels in the multivariate time series to have equal length.
We applied padding to the shorter channels with the constant value 100, which does not appear in the original time series and would not introduce new semantic meaning. 
It ensures the padding does not introduce ambiguity or interfere with the semantic meaning of the encoded nucleotide signals.

\subsection{Channel Importance Study}
We utilized three types of data as the input features for each instance.
They are (1) the RNA sequence, which consists of the primary strand and its complementary strand, (2) the secondary structure information, and (3) the base-pair probability sequence.
To input the data into our time series-based classifiers, we converted them into multivariate time series.
The primary strand and its complementary strand are each encoded into one or two channels, using the encoding methods in Table~\ref{tab:ts_encoding}.
For example, single value mapping encodes a strand in one channel, while grouped variable-length channel mapping encodes in two channels.
The secondary structure information is converted into a univariate time series.
The base-pair probability sequence is already in numerical form and does not require further transformation.
It can be used either as a standalone channel or incorporated into the encoding of the complementary strand.
We performed a channel importance study to determine the most informative combination of the above channels.

We referred to the multivariate time series that consists of the channels from the RNA sequence only as the baseline setting.
We added the other channels to this baseline.
It leads to the following configurations (cfgs):
\begin{enumerate}
  \item (cfg 1) Baseline: Time series derived only from the RNA sequence.
  \item (cfg 2) Baseline + Secondary structure: Baseline + time series representation of the secondary structure.
  \item (cfg 3) Baseline + Base-pair probability (Standalone): Baseline + the base-pair probability sequence as a standalone channel.
  \item (cfg 4) Baseline + Base-Pair probability (Incorporated): Baseline with the base-pair probability sequence incorporated into the encoding of the complementary strand.
\end{enumerate}


\input{../tables/channel_ablation}


We used single value mapping as the encoding method.
Table~\ref{tab:channel_ablation} shows the result.
From the table, we can see that the addition of secondary structure, base-pair probability as a standalone channel, and base-pair probability incorporated in the encoding of the complementary strand can improve the performance.
We plotted the critical difference (CD) diagram as shown in Figure~\ref{fig:channel_ablation_cd} to visualize Table~\ref{tab:channel_ablation} to make the performances of different combinations more obvious.
In CD diagrams, lower-ranked methods (toward the right) are better.
A horizontal bar connecting combinations indicates no statistically significant difference.
% \begin{figure}[htbp]
%     \centering
%     \begin{subfigure}[b]{0.3\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/channel_ablation_cd_5p.pdf}
%         \caption{5p arm}
%         % \label{fig:sub1}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.3\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/channel_ablation_cd_3p.pdf}
%         \caption{3p arm}
%         % \label{fig:sub2}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.3\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/channel_ablation_cd_multi.pdf}
%         \caption{multi-class}
%         % \label{fig:sub3}
%     \end{subfigure}
%     \caption{CD diagrams of channel ablation study.}
%     \label{fig:channel_ablation_cd}
% \end{figure}

\input{../figures/channel_ablation_cd}

From Figure~\ref{fig:channel_ablation_cd}, we can see that including time series derived from secondary structure information and base-pair probability as a separate channel can significantly improve the performance of the classifiers. 
Incorporating the base-pair probability sequence in the time series encoding of the complementary strand can also improve the classifier, but to a minor degree compared to serving as a standalone channel. 
In our downstream analysis, we adopted the combination of RNA sequence time series, secondary structure time series, and base-pair probability time series as our multivariate time series input, with 4 to 6 channels, depending on the encoding used.

\subsection{Predictive Performance}
The experiment was conducted on three datasets: the 5p arm, the 3p arm, and the multi-class datasets.
Recall that we have nine encoding methods and five ROCKET-based classifiers.
It results in 45 combinations of encoding methods and classifiers.


\input{../tables/results}

The result is shown in Table~\ref{tab:results}.
The best combination of encoding method and classifier is shown in Table~\ref{tab:results_best_minirocket_dicleave}.
For the 5p arm dataset, the best combination is ``Global Cumulative grouped fixed-length channel mapping + ROCKET''.
For all five classification metrics, it outperforms the state-of-the-art (SOTA) method, DiCleave.
For the 3p arm dataset, the best combination is ``Global Cumulative grouped fixed-length channel mapping + ROCKET''.
Out of the five classification metrics, it outperforms DiCleave, except in specificity.
For the multi-class dataset, the best combination is ``Global Cumulative grouped fixed-length channel mapping + ROCKET''.
For all five classification metrics, it outperforms DiCleave.
Note that for the 3p arm and the multi-class datasets, the combination of ``Cumulative grouped fixed-length channel mapping + ROKCET'' also attains the best result.

\input{../tables/results_best_minirocket_dicleave}


% \begin{figure}[htbp]
%     \centering
%     \begin{subfigure}[b]{0.3\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/best_classifier_cd_5p.pdf}
%         \caption{5p arm}
%         % \label{fig:sub1}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.3\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/best_classifier_cd_3p.pdf}
%         \caption{3p arm}
%         % \label{fig:sub2}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.3\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/best_classifier_cd_multi.pdf}
%         \caption{multi-class}
%         % \label{fig:sub3}
%     \end{subfigure}
%     \caption{CD diagrams to compare different classifiers.}
%     \label{fig:best_model_cd}
% \end{figure}

\input{../figures/best_model_cd}

% \begin{figure}[htbp]
%     \centering
%     \begin{subfigure}[b]{0.3\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/best_encoding_cd_5p.pdf}
%         \caption{5p arm}
%         % \label{fig:sub1}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.3\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/best_encoding_cd_3p.pdf}
%         \caption{3p arm}
%         % \label{fig:sub2}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.3\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/best_encoding_cd_multi.pdf}
%         \caption{multi-class}
%         % \label{fig:sub3}
%     \end{subfigure}
%     \caption{CD diagrams to compare different encoding methods.}
%     \label{fig:best_encoding_cd}
% \end{figure}

\input{../figures/best_encoding_cd}

To summarize Table~\ref{tab:results}, we plot the CD diagrams for finding the best classifier, which is ROCKET in all cases, as shown in Figure~\ref{fig:best_model_cd}, and the best encoding method, which is enc 9 in the 5p arm dataset and enc 7 for the others, as shown in Figure~\ref{fig:best_encoding_cd}.
It is suggested to use ROCKET as the baseline classifier.
For the encoding, it is suggested to use the global cumulative approach (enc 7 or enc 9).

\subsection{Running Time Analysis}
To compare the computational efficiency of MTSCCleav and DiCleave, we conducted a comparative analysis of their running times.
For DiCleave, we employed the code from its supporting website\footnote{\\\href{https://github.com/MGuard0303/DiCleave}{https://github.com/MGuard0303/DiCleave} (Accessed on: 2025-07-13).}, without any modifications.
All experiments were conducted on the same machine (a personal laptop equipped with an Apple M1 Pro chip and 16 GB of memory) and using the same splits of the training and test datasets under 5-fold cross-validation to ensure fairness.
The reported running times are the averages of the five runs.
The timing results were measured from the training phase to the return of the five classification metrics.
% We have ignored the computation time for raw input preprocessing because it is the shared part of both methods.
% The computation time for the time series encoding of MTSCCleav is also not included because they are simple $O(n)$ algorithms where $n$ is the size of the input.
The result is shown in Table~\ref{tab:results_best_minirocket_dicleave}.
MiniROCKET is the most computationally efficient of the five rocket-based classifiers.
We also included its best result, along with the corresponding encoding method, even though this combination may not be the best overall.

MTSCCleav demonstrated a significant advantage in computational efficiency, achieving an average 27.0X, 3.7X, and 10.7X speedup over DiCleave, for the 5p arm, 3p arm, and multi-class datasets, respectively.
If we consider using the MiniROCKET in the case of 3p arm and multi-class datasets, it achieves 16.1X and 28.8X speedup.
To note, in the case of the 3p arm dataset,  the performance of MiniROCKET is only slightly worse than DiCleave.
In the case of the multi-class dataset, even the performance of MiniROCKET is better than DiCleave.
DiCleave is a deep learning-based method that requires substantial time for model inference, while MTSCleav leverages efficient ROCKET-based classifiers.
This significant reduction in runtime makes MTSCCleav more suitable for large-scale data and real-time applications.

\subsection{Subsequence Importance}
To evaluate the sensitivity of MTSCCleav to subsequences of the input, we conducted a perturbation experiment to evaluate the importance of subsequences based on masking windows.
The goal of this experiment is to identify which subsequences of the entire time series are critical for classification.
We examine how various modifications to the original input impact model performance.
It suggests which features are essential for classification.

The model was trained on the original training dataset.
For each instance in the test dataset, we measure its original score and the masked score.
We slid a masking window $w$ with a fixed length over the input time series $T$.
$|w|$ was set to 4, which is about one third of the whole length.
For each window position $i \in \{1, 2, ..., |T|-|w|+1\}$, we masked all entries across all the channels of $T$ within the window.
Hence, we removed or hid that portion of information from the model during inference.
The changes in classification performance in terms of accuracy relative to the unmasked original score of each $i$ are recorded.
Intuitively, if the information of a subsequence is critical for the classification, the masking of this subsequence would lead to a great drop in classification performance.
We aggregated the importance score across the test dataset.
% \begin{figure}[htbp]
%     \centering
%     % Top subfigure
%     \begin{subfigure}[b]{0.8\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/perturbation_5p.pdf}
%         \caption{5p arm}
%         % \label{fig:top}
%     \end{subfigure}
%     \vspace{0.5cm}  % Space between the two
%     % Bottom subfigure
%     \begin{subfigure}[b]{0.8\textwidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/perturbation_3p.pdf}
%         \caption{3p arm}
%         % \label{fig:bottom}
%     \end{subfigure}
%     \caption{Results of the perturbation experiment.}
%     \label{fig:perturbation}
% \end{figure}

\input{../figures/perturbation}

The result is shown in Figure~\ref{fig:perturbation}.
For the encoding methods, we cannot use the methods derived from the cumulative mapping because the accumulation would leak information from the masked region.
We adopted ``Grouped fixed-length channel mapping'' as the encoding method and ROCKET as the classifier. 
``Grouped fixed-length channel mapping'' is the best encoding, other than the methods derived from the cumulative mapping, in all datasets, as shown in Figure~\ref{fig:best_encoding_cd}.
ROCKET is the best classifier, as shown in Figure~\ref{fig:best_model_cd}.

In the 5p arm dataset, we found that masking subsequences at the tailing part caused a significant drop in the importance score, as shown in Figure~\ref{fig:perturbation}~(a).
In the 3p arm dataset, we found that masking subsequences at the leading part caused a significant drop in the importance score, as shown in Figure~\ref{fig:perturbation}~(b).

\subsection{Summary}
Our method achieves better or comparable predictive results and a 3.7X to 28.8X speedup compared to the state-of-the-art (SOTA).